{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Introduction to Cross-Validation - Lab\n", "\n", "## Introduction\n", "\n", "In this lab, you'll be able to practice your cross-validation skills!\n", "\n", "\n", "## Objectives\n", "\n", "You will be able to:\n", "\n", "- Perform cross validation on a model\n", "- Compare and contrast model validation strategies"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Let's Get Started\n", "\n", "We included the code to pre-process the Ames Housing dataset below. This is done for the sake of expediency, although it may result in data leakage and therefore overly optimistic model metrics."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "ames = pd.read_csv('ames.csv')\n", "\n", "continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n", "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n", "\n", "ames_cont = ames[continuous]\n", "\n", "# log features\n", "log_names = [f'{column}_log' for column in ames_cont.columns]\n", "\n", "ames_log = np.log(ames_cont)\n", "ames_log.columns = log_names\n", "\n", "# normalize (subract mean and divide by std)\n", "\n", "def normalize(feature):\n", "    return (feature - feature.mean()) / feature.std()\n", "\n", "ames_log_norm = ames_log.apply(normalize)\n", "\n", "# one hot encode categoricals\n", "ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n", "\n", "preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)\n", "\n", "X = preprocessed.drop('SalePrice_log', axis=1)\n", "y = preprocessed['SalePrice_log']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train-Test Split\n", "\n", "Perform a train-test split with a test set of 20% and a random state of 4."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Fit a Model\n", "\n", "Fit a linear regression model on the training set"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/plain": ["LinearRegression()"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["linreg = LinearRegression()\n", "linreg.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Calculate MSE\n", "\n", "Calculate the mean squared error on the test set"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import mean_squared_error"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.15233997210708167"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "y_hat_test = linreg.predict(X_test)\n", "test_mse = mean_squared_error(y_test, y_hat_test)\n", "test_mse"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Cross-Validation using Scikit-Learn\n", "\n", "Now let's compare that single test MSE to a cross-validated test MSE."]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import cross_val_score"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0.12431546, 0.19350065, 0.1891053 , 0.17079325, 0.20742705])"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["cv_5_results = -cross_val_score(linreg, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n", "cv_5_results"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.17702834210001128"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["cv_5_results.mean()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compare and contrast the results. What is the difference between the train-test split and cross-validation results? Do you \"trust\" one more than the other?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\"\"\"\n", "Rounded to 1 decimal place, both the train-test split result and the cross-validation\n", "result would be 0.2\n", "\n", "However with more decimal places, the differences become apparent. The train-test split\n", "result is about 0.152 whereas the average cross-validation result is about 0.177. Because\n", "this is an error-based metric, a higher value is worse, so this means that the train-test\n", "split result is \"better\" (more optimistic)\n", "\n", "Another way to look at the results would be to compare the train-test split result to each\n", "of the 5 split results. Only 1 out of 5 splits has a better MSE than the train-test split,\n", "meaning that the average is not being skewed by just 1 or 2 values that are significantly\n", "worse than the train-test split result\n", "\n", "Taking the average as well as the spread into account, I would be more inclined to \"trust\"\n", "the cross-validated (less optimistic) score and assume that the performance on unseen data\n", "would be closer to 0.177 than 0.152\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Level Up: Let's Build It from Scratch!\n", "\n", "### Create a Cross-Validation Function\n", "\n", "Write a function `kfolds(data, k)` that splits a dataset into `k` evenly sized pieces. If the full dataset is not divisible by `k`, make the first few folds one larger then later ones.\n", "\n", "For example, if you had this dataset:"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>color</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>red</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>orange</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>yellow</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>green</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>blue</td>\n", "    </tr>\n", "    <tr>\n", "      <th>5</th>\n", "      <td>indigo</td>\n", "    </tr>\n", "    <tr>\n", "      <th>6</th>\n", "      <td>violet</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["    color\n", "0     red\n", "1  orange\n", "2  yellow\n", "3   green\n", "4    blue\n", "5  indigo\n", "6  violet"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["example_data = pd.DataFrame({\n", "    \"color\": [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"]\n", "})\n", "example_data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`kfolds(example_data, 3)` should return:\n", "\n", "* a dataframe with `red`, `orange`, `yellow`\n", "* a dataframe with `green`, `blue`\n", "* a dataframe with `indigo`, `violet`\n", "\n", "Because the example dataframe has 7 records, which is not evenly divisible by 3, so the \"leftover\" 1 record extends the length of the first dataframe."]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["    color\n", "0     red\n", "1  orange\n", "2  yellow \n", "\n", "   color\n", "3  green\n", "4   blue \n", "\n", "    color\n", "5  indigo\n", "6  violet \n", "\n"]}], "source": ["def kfolds(data, k):\n", "    folds = []\n", "    \n", "    # Calculate the fold size plus the remainder\n", "    num_observations = len(data)\n", "    small_fold_size = num_observations // k\n", "    large_fold_size = small_fold_size + 1\n", "    leftovers = num_observations % k\n", "    \n", "    start_index = 0\n", "    for fold_n in range(k):\n", "        # Select fold size based on whether or not all of the leftovers have been used up\n", "        if fold_n < leftovers:\n", "            fold_size = large_fold_size\n", "        else:\n", "            fold_size = small_fold_size\n", "        \n", "        # Get fold from dataframe and add it to the list\n", "        fold = data.iloc[start_index:start_index + fold_size]\n", "        folds.append(fold)\n", "        \n", "        # Move the start index to the start of the next fold\n", "        start_index += fold_size\n", "                    \n", "    return folds\n", "\n", "results = kfolds(example_data, 3)\n", "for result in results:\n", "    print(result, \"\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Apply Your Function to the Ames Housing Data\n", "\n", "Get folds for both `X` and `y`."]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["\n", "X_folds = kfolds(X, 5)\n", "y_folds = kfolds(y, 5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Perform a Linear Regression for Each Fold and Calculate the Test Error\n", "\n", "Remember that for each fold you will need to concatenate all but one of the folds to represent the training data, while the one remaining fold represents the test data."]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[0.12431546148437427, 0.19350064631313135, 0.18910530431311193, 0.17079325250026922, 0.20742704588916958]\n"]}], "source": ["test_errs = []\n", "k = 5\n", "\n", "for n in range(k):\n", "    # Split into train and test for the fold\n", "    X_train = pd.concat([fold for i, fold in enumerate(X_folds) if i!=n])\n", "    X_test = X_folds[n]\n", "    y_train = pd.concat([fold for i, fold in enumerate(y_folds) if i!=n])\n", "    y_test = y_folds[n]\n", "    \n", "    # Fit a linear regression model\n", "    linreg.fit(X_train, y_train)\n", "    \n", "    # Evaluate test errors\n", "    y_hat_test = linreg.predict(X_test)\n", "    test_residuals = y_hat_test - y_test\n", "    test_errs.append(np.mean(test_residuals.astype(float)**2))\n", "    \n", "print(test_errs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If your code was written correctly, these should be the same errors as scikit-learn produced with `cross_val_score` (within rounding error). Test this out below:"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Split 1\n", "My result:      0.1243\n", "sklearn result: 0.1243\n", "\n", "Split 2\n", "My result:      0.1935\n", "sklearn result: 0.1935\n", "\n", "Split 3\n", "My result:      0.1891\n", "sklearn result: 0.1891\n", "\n", "Split 4\n", "My result:      0.1708\n", "sklearn result: 0.1708\n", "\n", "Split 5\n", "My result:      0.2074\n", "sklearn result: 0.2074\n", "\n"]}], "source": ["\n", "for k in range(5):\n", "    print(f\"Split {k+1}\")\n", "    print(f\"My result:      {round(test_errs[k], 4)}\")\n", "    print(f\"sklearn result: {round(cv_5_results[k], 4)}\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This was a bit of work! Hopefully you have a clearer understanding of the underlying logic for cross-validation if you attempted this exercise."]}, {"cell_type": "markdown", "metadata": {}, "source": ["##  Summary "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Congratulations! You are now familiar with cross-validation and know how to use `cross_val_score()`. Remember that the results obtained from cross-validation are more robust than train-test split."]}], "metadata": {"kernelspec": {"display_name": "Python (learn-env)", "language": "python", "name": "learn-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 2}